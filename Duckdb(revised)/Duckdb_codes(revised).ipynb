{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Execution**"
      ],
      "metadata": {
        "id": "lpxRQPzLD-d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With connect duckdb (Not execute method)"
      ],
      "metadata": {
        "id": "w1nMEcek886b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1ZXGF8j8vNU"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Connect to DuckDB file database\n",
        "conn = duckdb.connect('inventory.db')  # <-- Your database is now 'inventory.db'\n",
        "\n",
        "# ✅ Step 2: CSV to Table mapping\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 3: Load and save each CSV as a DuckDB table\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, conn, if_exists='replace', index=False)\n",
        "        print(f\"✅ Imported {file} into table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped {file} — file not uploaded\")\n",
        "\n",
        "# ✅ Step 4: Reusable SQL query function\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 5: Show all tables and sample data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print('Count of records:', count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs imported into DuckDB database 'inventory.db'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For google collab 👇👇"
      ],
      "metadata": {
        "id": "ll_HU73y9JOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Install DuckDB in Google Colab (only once)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files  # for manual CSV uploads\n",
        "\n",
        "# ✅ Step 1: Upload your CSVs (manual upload in Colab UI)\n",
        "uploaded = files.upload()  # Upload the 6 CSVs here\n",
        "\n",
        "# ✅ Step 2: Connect to DuckDB (will create 'inventory.db' in Colab's filesystem)\n",
        "conn = duckdb.connect('inventory.db')\n",
        "\n",
        "# ✅ Step 3: Define filename-to-table mapping\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 4: Read CSVs and write to DuckDB\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, conn, if_exists='replace', index=False)\n",
        "        print(f\"✅ Imported {file} into table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped {file} — file not uploaded\")\n",
        "\n",
        "# ✅ Step 5: Reusable query runner\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 6: Show tables and sample data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print('Count of records:', count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs successfully imported into DuckDB database 'inventory.db'\")"
      ],
      "metadata": {
        "id": "9cV3b2O_9PPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With no connect 👇👇"
      ],
      "metadata": {
        "id": "dmjMGIi09Tlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using df.to_sql instead of duckdb.register👇👇👇 VSCode"
      ],
      "metadata": {
        "id": "mmvbmTD69aWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Define CSV filename-to-table mapping\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 2: Read and write each CSV as a DuckDB table\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, duckdb.connect(), if_exists='replace')\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Step 3: Reusable SQL query runner\n",
        "def run_query(query):\n",
        "    return duckdb.query(query).to_df()\n",
        "\n",
        "# ✅ Step 4: Show tables and display sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into in-memory DuckDB successfully!\")"
      ],
      "metadata": {
        "id": "pyE4f7WV9Xjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Collab 👇👇"
      ],
      "metadata": {
        "id": "32GTIruL9f-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (if not already)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ✅ Step 3: Upload CSV files manually from your local machine\n",
        "uploaded = files.upload()  # Upload the 6 CSVs when prompted\n",
        "\n",
        "# ✅ Step 4: Map filenames to DuckDB table names\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 5: Read each CSV and write to in-memory DuckDB tables\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, duckdb.connect(), if_exists='replace')\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Step 6: Define a reusable query runner\n",
        "def run_query(query):\n",
        "    return duckdb.query(query).to_df()\n",
        "\n",
        "# ✅ Step 7: Show all tables and preview sample data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print('Count of records:', count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All uploaded CSVs loaded into in-memory DuckDB session!\")"
      ],
      "metadata": {
        "id": "LZMQClok9eJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ---Using df.to_sql instead of duckdb.register👇👇👇 VSCode"
      ],
      "metadata": {
        "id": "mjcm5c5T9nBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Shared in-memory DuckDB connection\n",
        "conn = duckdb.connect()  # Optional: use 'inventory.duckdb' to persist\n",
        "\n",
        "# ✅ Define CSV filename-to-table mapping\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Read and write each CSV as a DuckDB table\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, conn, if_exists='replace')  # 🧠 shared connection\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Reusable SQL query runner using pandas\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Show tables and display sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into shared DuckDB session successfully!\")\n"
      ],
      "metadata": {
        "id": "uQPb8o2a9pRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In collab 👇👇👇"
      ],
      "metadata": {
        "id": "nAJibojqG3v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (if not already installed)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ✅ Step 3: Upload multiple CSV files from your local system\n",
        "uploaded = files.upload()  # Upload the 6 inventory CSVs when prompted\n",
        "\n",
        "# ✅ Step 4: Shared in-memory DuckDB connection\n",
        "conn = duckdb.connect()  # Use 'inventory.duckdb' for persistent file\n",
        "\n",
        "# ✅ Step 5: Map uploaded filenames to DuckDB table names\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 6: Load each CSV into DuckDB\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, conn, if_exists='replace')  # Use shared connection\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Step 7: Reusable query function\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 8: Show tables and preview data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All uploaded CSVs successfully loaded into DuckDB in Colab!\")\n"
      ],
      "metadata": {
        "id": "a9pBrRDTG2tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single csv 👇👇Vscode"
      ],
      "metadata": {
        "id": "R8_S6RwE9uTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Connect once to a DuckDB in-memory or persistent database\n",
        "conn = duckdb.connect()  # Use duckdb.connect('inventory.db') for persistent\n",
        "\n",
        "# ✅ Step 2: CSV file and table name\n",
        "csv_file = \"begin_inventory.csv\"\n",
        "table_name = \"begin_inventory\"\n",
        "\n",
        "# ✅ Step 3: Read CSV and write to DuckDB using df.to_sql()\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df.to_sql(table_name, conn, if_exists='replace')\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ Skipped '{csv_file}' — file not found\")\n",
        "\n",
        "# ✅ Step 4: Query runner using pandas.read_sql_query\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 5: Show tables and sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 CSV loaded into DuckDB successfully!\")\n"
      ],
      "metadata": {
        "id": "vTI99ZSa9uAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google collab 👇👇"
      ],
      "metadata": {
        "id": "xcCinLxp9xgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ✅ Step 3: Upload a single CSV file from your local system\n",
        "uploaded = files.upload()  # Upload when prompted (e.g., begin_inventory.csv)\n",
        "\n",
        "# ✅ Step 4: Connect to DuckDB (in-memory or to a file)\n",
        "conn = duckdb.connect()  # Use duckdb.connect('inventory.db') for file persistence\n",
        "\n",
        "# ✅ Step 5: Read the CSV and write to DuckDB using df.to_sql()\n",
        "csv_file = \"begin_inventory.csv\"  # Change to your uploaded filename\n",
        "table_name = \"begin_inventory\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df.to_sql(table_name, conn, if_exists='replace')\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ Skipped '{csv_file}' — file not found\")\n",
        "\n",
        "# ✅ Step 6: Define reusable query function using pandas\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 7: Show tables and sample data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 CSV loaded into DuckDB successfully in Colab!\")\n"
      ],
      "metadata": {
        "id": "aKbOLObB9zr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For kaggle without execute process 👇👇"
      ],
      "metadata": {
        "id": "3erk9AqlAyHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Connect to DuckDB file-based database (will be created in the output)\n",
        "conn = duckdb.connect('inventory.db')  # Persists as inventory.db in the working directory\n",
        "\n",
        "# ✅ Step 2: Kaggle-style CSV input path (update your dataset folder name here)\n",
        "input_path = \"../input/your-dataset-folder-name/\"\n",
        "\n",
        "# ✅ Step 3: CSV file to DuckDB table mapping\n",
        "csv_files = {\n",
        "    \"begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"end_inventory.csv\": \"end_inventory\",\n",
        "    \"purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"purchases.csv\": \"purchases\",\n",
        "    \"sales.csv\": \"sales\",\n",
        "    \"vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 4: Load each CSV and write to DuckDB\n",
        "for file, table in csv_files.items():\n",
        "    full_path = input_path + file\n",
        "    try:\n",
        "        df = pd.read_csv(full_path)\n",
        "        df.to_sql(table, conn, if_exists='replace', index=False)\n",
        "        print(f\"✅ Imported '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ File not found: {full_path}\")\n",
        "\n",
        "# ✅ Step 5: Query runner using pandas\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 6: Show tables and sample rows\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs successfully loaded into DuckDB → inventory.db\")\n"
      ],
      "metadata": {
        "id": "xjqVf1jnDft5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Connect to persistent DuckDB file\n",
        "conn = duckdb.connect(\"inventory.db\")  # This will be created in Kaggle's working directory\n",
        "\n",
        "# ✅ Step 2: Absolute CSV file paths (Kaggle-style)\n",
        "csv_files = {\n",
        "    \"/kaggle/input/inventory-dataset/begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"/kaggle/input/inventory-dataset/end_inventory.csv\": \"end_inventory\",\n",
        "    \"/kaggle/input/inventory-dataset/purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"/kaggle/input/inventory-dataset/purchases.csv\": \"purchases\",\n",
        "    \"/kaggle/input/inventory-dataset/sales.csv\": \"sales\",\n",
        "    \"/kaggle/input/inventory-dataset/vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 3: Read and save each CSV to DuckDB\n",
        "for file_path, table_name in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "        print(f\"✅ Imported '{file_path}' as table '{table_name}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file_path}' — file not found\")\n",
        "\n",
        "# ✅ Step 4: Reusable SQL query function\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "# ✅ Step 5: Show tables and preview records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All inventory CSVs loaded into DuckDB file: 'inventory.db'\")\n"
      ],
      "metadata": {
        "id": "Fh61ZuueA1WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pd.read_sql shows user future warnings\n"
      ],
      "metadata": {
        "id": "Q7pMhVHpTR23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execute Pattern**"
      ],
      "metadata": {
        "id": "9yRZ3cgP93aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In VSCODE 👇👇Execute pattern for connect db"
      ],
      "metadata": {
        "id": "89xKy0FJ995S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Define CSV files and their target table names\n",
        "csv_files = {\n",
        "    \"video_game_sales.csv\": \"video_game_sales\",\n",
        "    \"game_reviews.csv\": \"game_reviews\",\n",
        "    \"console_specs.csv\": \"console_specs\"\n",
        "}\n",
        "\n",
        "# ✅ Step 2: Connect to a persistent DuckDB database\n",
        "conn = duckdb.connect(\"gaming_data.duckdb\")  # Creates the file if not exists\n",
        "\n",
        "# ✅ Step 3: Load each CSV and write it as a DuckDB table using df.to_sql()\n",
        "for file, table_name in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table_name, conn, if_exists='replace')\n",
        "        print(f\"✅ Saved '{file}' to DuckDB table '{table_name}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ File '{file}' not found. Skipping...\")\n",
        "\n",
        "print(\"🎉 All CSV files successfully saved into 'gaming_data.duckdb'!\")\n",
        "\n",
        "# ✅ Step 4: Define a reusable query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 5: Example Query - Total Global Sales by Platform\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 6: Run and display the result\n",
        "result = run_query(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "BwzVsDOC97zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In collab 👇👇"
      ],
      "metadata": {
        "id": "tUAcsDeK-BVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB if needed\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ✅ Step 3: Upload CSV files from your local machine\n",
        "uploaded = files.upload()  # Upload your CSVs when prompted\n",
        "\n",
        "# ✅ Step 4: Define CSV file to table name mapping\n",
        "csv_files = {\n",
        "    \"video_game_sales.csv\": \"video_game_sales\",\n",
        "    \"game_reviews.csv\": \"game_reviews\",\n",
        "    \"console_specs.csv\": \"console_specs\"\n",
        "}\n",
        "\n",
        "# ✅ Step 5: Connect to a persistent DuckDB database\n",
        "conn = duckdb.connect(\"gaming_data.duckdb\")  # Saved in Colab session storage\n",
        "\n",
        "# ✅ Step 6: Read each CSV and store as a DuckDB table using df.to_sql()\n",
        "for file, table_name in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table_name, conn, if_exists='replace')\n",
        "        print(f\"✅ Saved '{file}' to DuckDB table '{table_name}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ '{file}' not found. Skipping...\")\n",
        "\n",
        "print(\"🎉 All uploaded CSVs saved into 'gaming_data.duckdb'\")\n",
        "\n",
        "# ✅ Step 7: Define reusable query runner\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 8: Sample query — total global sales by platform\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 9: Run and display result\n",
        "result = run_query(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Int6UnE8-DSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Vscode (execute) without connection db explicitly\n",
        "👇👇"
      ],
      "metadata": {
        "id": "qBxL9xGQ-Fk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Create a shared in-memory DuckDB connection\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Dictionary of CSV files and their table names\n",
        "csv_files = {\n",
        "    \"video_game_sales.csv\": \"video_game_sales\",\n",
        "    \"game_reviews.csv\": \"game_reviews\",\n",
        "    \"console_specs.csv\": \"console_specs\"\n",
        "}\n",
        "\n",
        "# ✅ Load CSVs into DataFrames and store them in DuckDB using df.to_sql()\n",
        "for file, table_name in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table_name, conn, if_exists='replace')  # Save into shared DuckDB connection\n",
        "        print(f\"✅ Loaded '{file}' as table '{table_name}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ File '{file}' not found. Skipping...\")\n",
        "\n",
        "# ✅ Reusable query runner using the shared connection\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Example query: Total global sales by platform\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Run and display result\n",
        "result = run_query(query)\n",
        "result"
      ],
      "metadata": {
        "id": "AYfTVhIL-ITA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Collab 👇👇"
      ],
      "metadata": {
        "id": "jntMDNz7-KaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ✅ Step 3: Upload CSVs from your local machine\n",
        "uploaded = files.upload()  # Upload CSVs when prompted\n",
        "\n",
        "# ✅ Step 4: Define CSV-to-table mapping\n",
        "csv_files = {\n",
        "    \"video_game_sales.csv\": \"video_game_sales\",\n",
        "    \"game_reviews.csv\": \"game_reviews\",\n",
        "    \"console_specs.csv\": \"console_specs\"\n",
        "}\n",
        "\n",
        "# ✅ Step 5: Create a shared DuckDB in-memory connection\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Step 6: Load CSVs and save to DuckDB using df.to_sql()\n",
        "for file, table_name in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table_name, conn, if_exists='replace')\n",
        "        print(f\"✅ Loaded '{file}' as table '{table_name}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ File '{file}' not found. Skipping...\")\n",
        "\n",
        "# ✅ Step 7: Reusable query runner\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 8: Example query – Total global sales by platform\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 9: Run and display result\n",
        "result = run_query(query)\n",
        "result"
      ],
      "metadata": {
        "id": "Yf0yWsBt-M3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single csv  in google collab (without connection db explicitly)👇👇👇"
      ],
      "metadata": {
        "id": "KYcVgA7o-SFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ✅ Step 3: Upload a single CSV file\n",
        "uploaded = files.upload()  # Upload one CSV file like 'video_game_sales.csv'\n",
        "\n",
        "# ✅ Step 4: Define filename and table name\n",
        "file = \"video_game_sales.csv\"\n",
        "table_name = \"video_game_sales\"\n",
        "\n",
        "# ✅ Step 5: Create a DuckDB in-memory connection\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Step 6: Read the CSV and save it as a table\n",
        "try:\n",
        "    df = pd.read_csv(file)\n",
        "    df.to_sql(table_name, conn, if_exists='replace')\n",
        "    print(f\"✅ Loaded '{file}' as DuckDB table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{file}' not found. Skipping...\")\n",
        "\n",
        "# ✅ Step 7: Reusable SQL query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 8: Example query – Total global sales by platform\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 9: Run and show result\n",
        "result = run_query(query)\n",
        "result"
      ],
      "metadata": {
        "id": "dirL5e-6-S4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In VScode 👇👇"
      ],
      "metadata": {
        "id": "WhiNNQdz-Xlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Import necessary libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 2: Define the CSV file and table name\n",
        "file = \"video_game_sales.csv\"\n",
        "table_name = \"video_game_sales\"\n",
        "\n",
        "# ✅ Step 3: Create an in-memory DuckDB connection (or save to file)\n",
        "conn = duckdb.connect()  # or duckdb.connect(\"gaming_data.duckdb\") to persist\n",
        "\n",
        "# ✅ Step 4: Load the CSV and save it to DuckDB as a table\n",
        "try:\n",
        "    df = pd.read_csv(file)\n",
        "    df.to_sql(table_name, conn, if_exists='replace')\n",
        "    print(f\"✅ Loaded '{file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{file}' not found.\")\n",
        "\n",
        "# ✅ Step 5: Define a reusable query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 6: Example SQL query\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 7: Execute and display results\n",
        "result = run_query(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "9iuKXMCH-YWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In kaggle 👇👇"
      ],
      "metadata": {
        "id": "DwlaAL-g-cTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (Kaggle already has it preinstalled, but safe to include)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 3: Load the CSV file\n",
        "file = \"/kaggle/input/video-game-sales-data/video_game_sales.csv\"  # adjust if needed\n",
        "table_name = \"video_game_sales\"\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "print(f\"✅ Loaded CSV with {len(df)} rows.\")\n",
        "\n",
        "# ✅ Step 4: Load DataFrame into DuckDB table using df.to_sql\n",
        "conn = duckdb.connect()  # In-memory DuckDB\n",
        "df.to_sql(table_name, conn, if_exists='replace')\n",
        "print(f\"✅ DataFrame saved as DuckDB table '{table_name}'\")\n",
        "\n",
        "# ✅ Step 5: Define a query runner\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 6: Example SQL query\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 7: Run and show result\n",
        "result = run_query(query)\n",
        "result.head(10)"
      ],
      "metadata": {
        "id": "VFJ-KJBM-dKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👇👇👇"
      ],
      "metadata": {
        "id": "wmUHqxsp-i3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (optional in Kaggle)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 3: Define your file and table name\n",
        "file = \"/kaggle/input/inventory-data/sales.csv\"  # ✅ Change to your actual CSV path\n",
        "table_name = \"sales\"\n",
        "\n",
        "# ✅ Step 4: Connect to DuckDB file (creates inventory.db)\n",
        "conn = duckdb.connect(\"inventory.db\")  # This creates a persistent file in the working directory\n",
        "\n",
        "# ✅ Step 5: Read CSV and load into DuckDB using df.to_sql\n",
        "df = pd.read_csv(file)\n",
        "df.to_sql(table_name, conn, if_exists='replace')\n",
        "print(f\"✅ '{file}' loaded into 'inventory.db' as table '{table_name}'\")\n",
        "\n",
        "# ✅ Step 6: Define reusable SQL query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Step 7: Example query\n",
        "query = \"\"\"\n",
        "SELECT Product, SUM(Quantity) AS total_sold\n",
        "FROM sales\n",
        "GROUP BY Product\n",
        "ORDER BY total_sold DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Step 8: Run and display result\n",
        "result = run_query(query)\n",
        "result.head()"
      ],
      "metadata": {
        "id": "FE6ofCKO-lOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multicsv:👇👇"
      ],
      "metadata": {
        "id": "osx9T7KwAqvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (Kaggle already has it, just in case)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 3: Define CSV files and their corresponding table names\n",
        "csv_files = {\n",
        "    \"/kaggle/input/inventory-dataset/begin_inventory.csv\": \"begin_inventory\",\n",
        "    \"/kaggle/input/inventory-dataset/end_inventory.csv\": \"end_inventory\",\n",
        "    \"/kaggle/input/inventory-dataset/purchase_prices.csv\": \"purchase_prices\",\n",
        "    \"/kaggle/input/inventory-dataset/purchases.csv\": \"purchases\",\n",
        "    \"/kaggle/input/inventory-dataset/sales.csv\": \"sales\",\n",
        "    \"/kaggle/input/inventory-dataset/vendor_invoice.csv\": \"vendor_invoice\"\n",
        "}\n",
        "\n",
        "# ✅ Step 4: Connect to DuckDB file (persistent)\n",
        "conn = duckdb.connect(\"inventory.db\")\n",
        "\n",
        "# ✅ Step 5: Read CSVs and load into DuckDB using to_sql\n",
        "for file, table in csv_files.items():\n",
        "    df = pd.read_csv(file)\n",
        "    df.to_sql(table, conn, if_exists='replace')\n",
        "    print(f\"✅ Saved '{file}' to table '{table}' in inventory.db\")\n",
        "\n",
        "# ✅ Step 6: Optional query example\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# 🎯 Sample Query\n",
        "result = run_query(\"SELECT COUNT(*) FROM sales\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "ZmPjQ3RFArsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Final Suggestion (Clean Version Without Warning)"
      ],
      "metadata": {
        "id": "NHqFDNphHUcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "conn = duckdb.connect()\n",
        "\n",
        "csv_files = {\n",
        "    \"customers.csv\": \"customers\",\n",
        "    \"order_items.csv\": \"order_items\",\n",
        "    \"orders.csv\": \"orders\",\n",
        "    \"payments.csv\": \"payments\",\n",
        "    \"products.csv\": \"products\"\n",
        "}\n",
        "\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        conn.register(f\"{table}_df\", df)\n",
        "        conn.execute(f\"CREATE OR REPLACE TABLE {table} AS SELECT * FROM {table}_df\")\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into DuckDB with no warnings!\")\n"
      ],
      "metadata": {
        "id": "iD9DixQCHVNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IN Collab"
      ],
      "metadata": {
        "id": "YR4dH3i2JnY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Step 3: Upload CSV files manually when prompted\n",
        "uploaded = files.upload()  # 📂 Upload multiple files like customers.csv, orders.csv, etc.\n",
        "\n",
        "# ✅ Step 4: Connect to DuckDB (in-memory)\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Step 5: CSV filename-to-table mapping\n",
        "csv_files = {\n",
        "    \"customers.csv\": \"customers\",\n",
        "    \"order_items.csv\": \"order_items\",\n",
        "    \"orders.csv\": \"orders\",\n",
        "    \"payments.csv\": \"payments\",\n",
        "    \"products.csv\": \"products\"\n",
        "}\n",
        "\n",
        "# ✅ Step 6: Register CSVs as DuckDB tables\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        conn.register(f\"{table}_df\", df)\n",
        "        conn.execute(f\"CREATE OR REPLACE TABLE {table} AS SELECT * FROM {table}_df\")\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Step 7: Reusable query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Step 8: Show tables and display sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into DuckDB with no warnings!\")\n"
      ],
      "metadata": {
        "id": "UIQ_4VMHJmjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In kaggle"
      ],
      "metadata": {
        "id": "RZRrFTBdOOhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (usually preinstalled in Kaggle, but safe to include)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Step 3: Connect to DuckDB (in-memory or use 'your_file.duckdb' to persist)\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Step 4: CSV filename-to-table mapping\n",
        "# 🔁 Make sure these paths match your dataset folder in /kaggle/input/\n",
        "csv_files = {\n",
        "    \"/kaggle/input/your-dataset-folder/customers.csv\": \"customers\",\n",
        "    \"/kaggle/input/your-dataset-folder/order_items.csv\": \"order_items\",\n",
        "    \"/kaggle/input/your-dataset-folder/orders.csv\": \"orders\",\n",
        "    \"/kaggle/input/your-dataset-folder/payments.csv\": \"payments\",\n",
        "    \"/kaggle/input/your-dataset-folder/products.csv\": \"products\"\n",
        "}\n",
        "\n",
        "# ✅ Step 5: Register CSVs as DuckDB tables\n",
        "for file_path, table_name in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        conn.register(f\"{table_name}_df\", df)\n",
        "        conn.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {table_name}_df\")\n",
        "        print(f\"✅ Loaded '{file_path}' into DuckDB as table '{table_name}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file_path}' — file not found\")\n",
        "\n",
        "# ✅ Step 6: Reusable SQL query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Step 7: Show tables and sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into DuckDB with no warnings!\")\n"
      ],
      "metadata": {
        "id": "AcOfcsm7OQP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Csv"
      ],
      "metadata": {
        "id": "eKWDmDfYHlz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VSCode"
      ],
      "metadata": {
        "id": "sLen8mFCOYaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Step 1: Connect to DuckDB (in-memory or use 'inventory.duckdb' to persist)\n",
        "conn = duckdb.connect()  # or duckdb.connect('inventory.duckdb')\n",
        "\n",
        "# ✅ Step 2: Define CSV file and table name\n",
        "csv_file = \"customers.csv\"          # 🔁 Change this as needed\n",
        "table_name = \"customers\"\n",
        "\n",
        "# ✅ Step 3: Load CSV and write to DuckDB using DuckDB-native method\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    conn.register(f\"{table_name}_df\", df)  # 🧠 Register DataFrame using table_name\n",
        "    conn.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {table_name}_df\")\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ Skipped '{csv_file}' — file not found\")\n",
        "\n",
        "# ✅ Step 4: Reusable SQL query function\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Step 5: Show tables and sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 Single CSV loaded into DuckDB successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FCL1hvDDHnz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IN collab"
      ],
      "metadata": {
        "id": "mIOXAMgAJ5b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB in Colab (if not already)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Step 3: Upload CSV file manually from local machine\n",
        "uploaded = files.upload()  # 📂 Prompt to upload e.g., customers.csv\n",
        "\n",
        "# ✅ Step 4: Define filename and target table name\n",
        "csv_file = \"customers.csv\"       # 👈 Change to match uploaded filename\n",
        "table_name = \"customers\"\n",
        "\n",
        "# ✅ Step 5: Connect to DuckDB (in-memory or persistent if needed)\n",
        "conn = duckdb.connect()  # Or use: duckdb.connect('inventory.duckdb')\n",
        "\n",
        "# ✅ Step 6: Read, register, and create DuckDB table\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    conn.register(f\"{table_name}_df\", df)  # 🔁 Dynamic DataFrame registration\n",
        "    conn.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {table_name}_df\")\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{csv_file}' not found. Please upload the correct file.\")\n",
        "\n",
        "# ✅ Step 7: Define SQL query runner\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Step 8: Show tables and preview data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 Single CSV loaded into DuckDB successfully in Colab!\")\n"
      ],
      "metadata": {
        "id": "BlhlpAm1J7Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In kaggle"
      ],
      "metadata": {
        "id": "A4TsDxtmN7J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Install DuckDB (already available in Kaggle, but safe to include)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Step 2: Import required libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Step 3: Define path to your CSV file (e.g., in /kaggle/input/...)\n",
        "csv_file = \"/kaggle/input/your-dataset-folder/customers.csv\"  # ⛔ CHANGE this to match your dataset path\n",
        "table_name = \"customers\"\n",
        "\n",
        "# ✅ Step 4: Connect to DuckDB (in-memory or save as .duckdb file)\n",
        "conn = duckdb.connect()  # or duckdb.connect('inventory.duckdb')\n",
        "\n",
        "# ✅ Step 5: Read, register, and create table\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    conn.register(f\"{table_name}_df\", df)\n",
        "    conn.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {table_name}_df\")\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{csv_file}' not found. Make sure the path is correct.\")\n",
        "\n",
        "# ✅ Step 6: Define query runner\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Step 7: Show tables and preview data\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 Single CSV loaded into DuckDB successfully in Kaggle!\")\n"
      ],
      "metadata": {
        "id": "B_TFKI4yN8UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AFTER STEP-6\n",
        "\n",
        "# 🎯 Query: Total global sales by platform\n",
        "query = \"\"\"\n",
        "SELECT Platform, SUM(Global_Sales) AS total_sales\n",
        "FROM video_game_sales\n",
        "GROUP BY Platform\n",
        "ORDER BY total_sales DESC\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Execute and print result\n",
        "result = run_query(query)\n",
        "print(\"\\n🎮 Total Global Sales by Platform:\\n\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "FCmp-ZmxOjQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Full Example with Warning Suppressed"
      ],
      "metadata": {
        "id": "R1Cg4bcIPLEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Suppress UserWarnings (e.g., from pandas with DuckDB connection)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ✅ Connect to DuckDB\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Example CSV (change path as needed)\n",
        "csv_file = \"customers.csv\"\n",
        "table_name = \"customers\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    conn.register(f\"{table_name}_df\", df)\n",
        "    conn.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {table_name}_df\")\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{csv_file}' not found.\")\n",
        "\n",
        "# ✅ SQL query function\n",
        "def run_query(query):\n",
        "    return pd.read_sql_query(query, conn)  # ✅ Warning suppressed here\n",
        "\n",
        "# ✅ Show tables and preview\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All done with warnings suppressed!\")\n"
      ],
      "metadata": {
        "id": "YNOzIH56PL5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Suppress UserWarnings (e.g., from pandas with DuckDB connection)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ✅ Connect to DuckDB\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Example CSV (change path as needed)\n",
        "csv_file = \"customers.csv\"\n",
        "table_name = \"customers\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    conn.register(f\"{table_name}_df\", df)\n",
        "    conn.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM {table_name}_df\")\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{csv_file}' not found.\")\n",
        "\n",
        "# ✅ Define query runner using DuckDB-native fetchdf\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Show tables and preview\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All done with warnings suppressed!\")\n"
      ],
      "metadata": {
        "id": "LZkPudaoRRnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "x3alhLP0SEWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MULTICSV**"
      ],
      "metadata": {
        "id": "hLNtsVLESb2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VSCODE"
      ],
      "metadata": {
        "id": "BdONttcLSYFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "\n",
        "# ✅ Suppress UserWarnings from pandas about DuckDB connection\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ✅ Shared in-memory DuckDB connection\n",
        "conn = duckdb.connect()  # Optional: use 'inventory.duckdb' to persist\n",
        "\n",
        "# ✅ Define CSV filename-to-table mapping\n",
        "csv_files = {\n",
        "    \"customers.csv\": \"customers\",\n",
        "    \"order_items.csv\": \"order_items\",\n",
        "    \"orders.csv\": \"orders\",\n",
        "    \"payments.csv\": \"payments\",\n",
        "    \"products.csv\": \"products\"\n",
        "}\n",
        "\n",
        "# ✅ Read and write each CSV as a DuckDB table using df.to_sql()\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, conn, if_exists='replace')  # ✅ Using df.to_sql()\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Reusable SQL query runner using DuckDB-native method\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()  # ✅ No pandas SQL warnings\n",
        "\n",
        "# ✅ Show tables and display sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into DuckDB using df.to_sql(), with warnings suppressed!\")\n"
      ],
      "metadata": {
        "id": "1F0W19OJSBjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In collab"
      ],
      "metadata": {
        "id": "PO4rKeLzSUPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Install DuckDB (only needed once in Colab)\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Import libraries\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "\n",
        "# ✅ Suppress UserWarnings from pandas about DuckDB connection\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ✅ Shared in-memory DuckDB connection\n",
        "conn = duckdb.connect()\n",
        "\n",
        "# ✅ Upload CSVs to Colab (run this cell first and select files)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # 👈 Choose your 5 CSVs manually here\n",
        "\n",
        "# ✅ Define CSV filename-to-table mapping (must match uploaded filenames)\n",
        "csv_files = {\n",
        "    \"customers.csv\": \"customers\",\n",
        "    \"order_items.csv\": \"order_items\",\n",
        "    \"orders.csv\": \"orders\",\n",
        "    \"payments.csv\": \"payments\",\n",
        "    \"products.csv\": \"products\"\n",
        "}\n",
        "\n",
        "# ✅ Read and write each CSV as a DuckDB table using df.to_sql()\n",
        "for file, table in csv_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        df.to_sql(table, conn, if_exists='replace')  # ✅ Use df.to_sql()\n",
        "        print(f\"✅ Loaded '{file}' into DuckDB as table '{table}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ Skipped '{file}' — file not found\")\n",
        "\n",
        "# ✅ Define SQL query runner using DuckDB-native method\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Display all tables and preview sample rows\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 All CSVs loaded into DuckDB using df.to_sql(), with warnings suppressed!\")\n"
      ],
      "metadata": {
        "id": "Z9gb80ozSVtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single CSV (VSCODE)"
      ],
      "metadata": {
        "id": "akIbbV6GSrX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "\n",
        "# ✅ Suppress UserWarnings from pandas about DuckDB connection\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ✅ Connect to DuckDB (in-memory or persistent if desired)\n",
        "conn = duckdb.connect()  # Optional: use 'inventory.duckdb'\n",
        "\n",
        "# ✅ Define the CSV file and DuckDB table name\n",
        "csv_file = \"customers.csv\"\n",
        "table_name = \"customers\"\n",
        "\n",
        "# ✅ Read and load the CSV into DuckDB\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df.to_sql(table_name, conn, if_exists='replace')  # ✅ Using df.to_sql()\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{csv_file}' not found!\")\n",
        "\n",
        "# ✅ Reusable SQL query runner using DuckDB-native method\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Show the table and display sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 Single CSV loaded into DuckDB using df.to_sql(), with warnings suppressed!\")\n"
      ],
      "metadata": {
        "id": "vTihU7L3SuDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In collab"
      ],
      "metadata": {
        "id": "ezcB1-CfS7Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Install DuckDB in Colab if not already\n",
        "!pip install duckdb --quiet\n",
        "\n",
        "# ✅ Import modules\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from IPython.display import display\n",
        "\n",
        "# ✅ Suppress UserWarnings from pandas with DuckDB connection\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ✅ Connect to DuckDB (in-memory or persist with a filename)\n",
        "conn = duckdb.connect()  # You can use 'mydb.duckdb' to persist\n",
        "\n",
        "# ✅ Upload the file from local (optional step for Colab)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # 📁 Upload your 'customers.csv' file\n",
        "\n",
        "# ✅ Define single CSV file and DuckDB table name\n",
        "csv_file = \"customers.csv\"\n",
        "table_name = \"customers\"\n",
        "\n",
        "# ✅ Read and load the CSV using df.to_sql()\n",
        "try:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df.to_sql(table_name, conn, if_exists='replace')  # ✅ df.to_sql() with DuckDB\n",
        "    print(f\"✅ Loaded '{csv_file}' into DuckDB as table '{table_name}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠️ File '{csv_file}' not found!\")\n",
        "\n",
        "# ✅ SQL query runner\n",
        "def run_query(query):\n",
        "    return conn.execute(query).fetchdf()\n",
        "\n",
        "# ✅ Show tables and preview sample records\n",
        "tables = run_query(\"SHOW TABLES\")\n",
        "for table in tables['name']:\n",
        "    print('-'*50, f'{table}', '-'*50)\n",
        "    count = run_query(f\"SELECT COUNT(*) AS count FROM {table}\")['count'].values[0]\n",
        "    print(\"Count of records:\", count)\n",
        "    display(run_query(f\"SELECT * FROM {table} LIMIT 5\"))\n",
        "\n",
        "print(\"🎉 Done! Single CSV loaded into DuckDB using df.to_sql(), and preview displayed.\")\n"
      ],
      "metadata": {
        "id": "PVZQeXyrS8P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can use execute - pd sql or df-sql - pd-sql and you can use execute-execute or df-sql - execute  "
      ],
      "metadata": {
        "id": "6xOW-40KUnGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "its better to use execute-execute i.e register process to avoid future warnings."
      ],
      "metadata": {
        "id": "pV4gdRdHVCf_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avE8gqc0VB3-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}